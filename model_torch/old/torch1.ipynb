{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#https://colab.research.google.com/drive/1N3LvAO0AXV4kBPbTMX866OwJM9YS6Ji2?usp=sharing#scrollTo=fl5W1gg5Jhzz\n",
    "\n",
    "df_players = pd.read_csv(\"./../data_scrapped/atp_players.csv\")\n",
    "df_matchs = pd.read_csv(\"./../data_formatted/training_dgl_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On construit le graph\n",
    "\n",
    "# lecture des données attendues\n",
    "# tensor1[1] -> tensor2[1] \n",
    "# le player index en tensor1 a joué contre le player au meme index en tensor 2\n",
    "# y stocke le résultat du match\n",
    "\n",
    "\n",
    "tensor1=[]\n",
    "tensor2=[]\n",
    "\n",
    "for index,row in df_players.iterrows():\n",
    "    winmatchs = df_matchs[df_matchs.player1_id == row.player_id]\n",
    "    #print(len(winmatchs))\n",
    "    if len(winmatchs) > 0:\n",
    "        #print(row.player_id)\n",
    "        for index2, row2 in winmatchs.iterrows():\n",
    "                tensor1.append(index)\n",
    "                tensor2.append(df_players.loc[df_players.player_id == row2.player2_id].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "\n",
    "labels = numpy.ones(len(tensor1))\n",
    "\n",
    "indexes = random.sample(range(0, len(tensor1)-1), ((len(tensor1)-1)//2))\n",
    "\n",
    "for index in indexes:\n",
    "    temp = tensor1[index]\n",
    "    tensor1[index] = tensor2[index]\n",
    "    tensor2[index] = temp\n",
    "    labels[index] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3446, 3], edge_index=[2, 51981], y=[51981])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Create the heterogeneous graph data object:\n",
    "#data = Data()\n",
    "\n",
    "# Add the user nodes:\n",
    "x = torch.Tensor(list(df_players[[\"birth_year\",\"weight_kg\",\"height_cm\"]].values))  # [num_users, num_features_users]\n",
    "x = torch.nan_to_num(x, nan=0.0)\n",
    "#x = torch.masked_select(x, ~torch.isnan(x))\n",
    "#x = torch.ones(df_players.shape[0])\n",
    "\n",
    "edge_index = torch.stack([torch.tensor(tensor1), torch.tensor(tensor2)], dim=0)\n",
    "#edge_attr = torch.Tensor(list(df_matchs[[\"player1_atprank\",\"player1_oddsB365\",\"player2_atprank\",\"player2_oddsB365\"]].values))\n",
    "#y = torch.Tensor(list(df_matchs[[\"winner_player1\"]].values))\n",
    "\n",
    "labels = torch.Tensor(labels)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index,y=labels) \n",
    "#data = T.ToUndirected()(data)\n",
    "# Add the movie nodes:\n",
    "#data['movie'].x = movie_features  # [num_movies, num_features_movies]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[3446, 3], edge_index=[2, 44184], y=[44184], edge_label=[44184], edge_label_index=[2, 44184]),\n",
       " Data(x=[3446, 3], edge_index=[2, 44184], y=[44184], edge_label=[5198], edge_label_index=[2, 5198]),\n",
       " Data(x=[3446, 3], edge_index=[2, 46783], y=[46783], edge_label=[10396], edge_label_index=[2, 10396]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.05,\n",
    "    num_test=0.1,\n",
    "    is_undirected=False,\n",
    "    add_negative_train_samples=False\n",
    ")(data)\n",
    "train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1.,  ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "\n",
    "model = Net(3, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 1036127.6250, Val: 0.5516, Test: 0.5518\n",
      "Epoch: 002, Loss: 268880.0312, Val: 0.5052, Test: 0.5061\n",
      "Epoch: 003, Loss: 91835.0625, Val: 0.5023, Test: 0.5015\n",
      "Epoch: 004, Loss: 167672.4375, Val: 0.5023, Test: 0.5015\n",
      "Epoch: 005, Loss: 217630.3125, Val: 0.5023, Test: 0.5015\n",
      "Epoch: 006, Loss: 192884.5156, Val: 0.5023, Test: 0.5015\n",
      "Epoch: 007, Loss: 141116.1250, Val: 0.5029, Test: 0.5017\n",
      "Epoch: 008, Loss: 97546.5547, Val: 0.5081, Test: 0.5092\n",
      "Epoch: 009, Loss: 71924.5547, Val: 0.5127, Test: 0.5140\n",
      "Epoch: 010, Loss: 57384.6484, Val: 0.5314, Test: 0.5321\n",
      "Epoch: 011, Loss: 48634.3438, Val: 0.5516, Test: 0.5518\n",
      "Epoch: 012, Loss: 41472.3477, Val: 0.5516, Test: 0.5518\n",
      "Epoch: 013, Loss: 35145.1094, Val: 0.5516, Test: 0.5518\n",
      "Epoch: 014, Loss: 30195.1191, Val: 0.5516, Test: 0.5518\n",
      "Epoch: 015, Loss: 26385.5605, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 016, Loss: 24134.5625, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 017, Loss: 22563.0293, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 018, Loss: 21416.0703, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 019, Loss: 20051.4102, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 020, Loss: 18462.1523, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 021, Loss: 16675.2734, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 022, Loss: 14565.6270, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 023, Loss: 12473.1484, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 024, Loss: 10549.7393, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 025, Loss: 8876.6982, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 026, Loss: 7534.4141, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 027, Loss: 6370.6914, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 028, Loss: 5422.5718, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 029, Loss: 4621.1426, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 030, Loss: 3979.4124, Val: 0.5518, Test: 0.5518\n",
      "Epoch: 031, Loss: 3501.9602, Val: 0.5535, Test: 0.5543\n",
      "Epoch: 032, Loss: 3079.6641, Val: 0.5835, Test: 0.5824\n",
      "Epoch: 033, Loss: 2775.5706, Val: 0.6867, Test: 0.6854\n",
      "Epoch: 034, Loss: 2516.7119, Val: 0.7145, Test: 0.7124\n",
      "Epoch: 035, Loss: 2430.5388, Val: 0.7184, Test: 0.7180\n",
      "Epoch: 036, Loss: 2367.3318, Val: 0.7191, Test: 0.7185\n",
      "Epoch: 037, Loss: 2373.4041, Val: 0.7187, Test: 0.7167\n",
      "Epoch: 038, Loss: 2325.8564, Val: 0.7181, Test: 0.7152\n",
      "Epoch: 039, Loss: 2302.6907, Val: 0.7184, Test: 0.7151\n",
      "Epoch: 040, Loss: 2273.6926, Val: 0.7189, Test: 0.7171\n",
      "Epoch: 041, Loss: 2194.9282, Val: 0.7218, Test: 0.7218\n",
      "Epoch: 042, Loss: 2136.0415, Val: 0.7243, Test: 0.7246\n",
      "Epoch: 043, Loss: 2073.1592, Val: 0.7281, Test: 0.7284\n",
      "Epoch: 044, Loss: 1971.4325, Val: 0.7324, Test: 0.7337\n",
      "Epoch: 045, Loss: 1861.4233, Val: 0.7374, Test: 0.7384\n",
      "Epoch: 046, Loss: 1760.6091, Val: 0.7412, Test: 0.7417\n",
      "Epoch: 047, Loss: 1657.8921, Val: 0.7447, Test: 0.7428\n",
      "Epoch: 048, Loss: 1579.7385, Val: 0.7467, Test: 0.7456\n",
      "Epoch: 049, Loss: 1482.3173, Val: 0.7476, Test: 0.7467\n",
      "Epoch: 050, Loss: 1399.3120, Val: 0.7488, Test: 0.7479\n",
      "Epoch: 051, Loss: 1349.6125, Val: 0.7491, Test: 0.7496\n",
      "Epoch: 052, Loss: 1278.5908, Val: 0.7504, Test: 0.7497\n",
      "Epoch: 053, Loss: 1206.7048, Val: 0.7508, Test: 0.7506\n",
      "Epoch: 054, Loss: 1162.5261, Val: 0.7510, Test: 0.7511\n",
      "Epoch: 055, Loss: 1130.0468, Val: 0.7515, Test: 0.7517\n",
      "Epoch: 056, Loss: 1062.0149, Val: 0.7518, Test: 0.7519\n",
      "Epoch: 057, Loss: 1012.4470, Val: 0.7518, Test: 0.7524\n",
      "Epoch: 058, Loss: 951.6898, Val: 0.7521, Test: 0.7527\n",
      "Epoch: 059, Loss: 915.9384, Val: 0.7522, Test: 0.7528\n",
      "Epoch: 060, Loss: 880.2668, Val: 0.7524, Test: 0.7527\n",
      "Epoch: 061, Loss: 839.9326, Val: 0.7526, Test: 0.7527\n",
      "Epoch: 062, Loss: 795.9558, Val: 0.7529, Test: 0.7530\n",
      "Epoch: 063, Loss: 753.1773, Val: 0.7531, Test: 0.7535\n",
      "Epoch: 064, Loss: 727.7379, Val: 0.7532, Test: 0.7537\n",
      "Epoch: 065, Loss: 693.5105, Val: 0.7531, Test: 0.7538\n",
      "Epoch: 066, Loss: 656.0465, Val: 0.7533, Test: 0.7542\n",
      "Epoch: 067, Loss: 644.5149, Val: 0.7532, Test: 0.7540\n",
      "Epoch: 068, Loss: 609.0062, Val: 0.7532, Test: 0.7542\n",
      "Epoch: 069, Loss: 586.2368, Val: 0.7531, Test: 0.7544\n",
      "Epoch: 070, Loss: 559.9752, Val: 0.7530, Test: 0.7547\n",
      "Epoch: 071, Loss: 542.9277, Val: 0.7532, Test: 0.7548\n",
      "Epoch: 072, Loss: 523.7136, Val: 0.7535, Test: 0.7548\n",
      "Epoch: 073, Loss: 491.5432, Val: 0.7535, Test: 0.7548\n",
      "Epoch: 074, Loss: 487.4609, Val: 0.7535, Test: 0.7550\n",
      "Epoch: 075, Loss: 466.9952, Val: 0.7537, Test: 0.7551\n",
      "Epoch: 076, Loss: 445.6941, Val: 0.7541, Test: 0.7552\n",
      "Epoch: 077, Loss: 430.8426, Val: 0.7543, Test: 0.7552\n",
      "Epoch: 078, Loss: 424.6051, Val: 0.7543, Test: 0.7552\n",
      "Epoch: 079, Loss: 404.9580, Val: 0.7543, Test: 0.7555\n",
      "Epoch: 080, Loss: 389.1635, Val: 0.7545, Test: 0.7556\n",
      "Epoch: 081, Loss: 383.1702, Val: 0.7545, Test: 0.7557\n",
      "Epoch: 082, Loss: 369.7043, Val: 0.7545, Test: 0.7557\n",
      "Epoch: 083, Loss: 355.8435, Val: 0.7549, Test: 0.7558\n",
      "Epoch: 084, Loss: 337.0103, Val: 0.7549, Test: 0.7558\n",
      "Epoch: 085, Loss: 333.8614, Val: 0.7549, Test: 0.7558\n",
      "Epoch: 086, Loss: 323.4497, Val: 0.7549, Test: 0.7559\n",
      "Epoch: 087, Loss: 313.9908, Val: 0.7551, Test: 0.7560\n",
      "Epoch: 088, Loss: 302.5590, Val: 0.7552, Test: 0.7560\n",
      "Epoch: 089, Loss: 295.4937, Val: 0.7553, Test: 0.7560\n",
      "Epoch: 090, Loss: 284.6455, Val: 0.7553, Test: 0.7560\n",
      "Epoch: 091, Loss: 273.6310, Val: 0.7553, Test: 0.7562\n",
      "Epoch: 092, Loss: 270.4803, Val: 0.7553, Test: 0.7562\n",
      "Epoch: 093, Loss: 257.2664, Val: 0.7555, Test: 0.7562\n",
      "Epoch: 094, Loss: 253.9672, Val: 0.7555, Test: 0.7562\n",
      "Epoch: 095, Loss: 245.9478, Val: 0.7555, Test: 0.7562\n",
      "Epoch: 096, Loss: 241.3980, Val: 0.7554, Test: 0.7562\n",
      "Epoch: 097, Loss: 232.7567, Val: 0.7556, Test: 0.7563\n",
      "Epoch: 098, Loss: 230.5906, Val: 0.7558, Test: 0.7568\n",
      "Epoch: 099, Loss: 218.9080, Val: 0.7558, Test: 0.7568\n",
      "Epoch: 100, Loss: 217.7347, Val: 0.7558, Test: 0.7568\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16474\n",
      "16474\n",
      "51981\n",
      "0.6338469825513168\n"
     ]
    }
   ],
   "source": [
    "print(len(df_matchs[(df_matchs.player1_oddsB365 < df_matchs.player2_oddsB365) & (df_matchs.winner_player1 == 1)]))\n",
    "print(len(df_matchs[(df_matchs.player1_oddsB365 > df_matchs.player2_oddsB365) & (df_matchs.winner_player1 == 0)]))\n",
    "print(len(df_matchs))\n",
    "print(16474 * 2 / 51981)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2000, 3415],\n",
      "        [3415, 2000]])\n",
      "tensor([1180.3882, 1180.3882])\n"
     ]
    }
   ],
   "source": [
    "# Specify the edge you want to predict (e.g., edge from node 0 to node 1)\n",
    "node_0 = 2000\n",
    "node_1 = 3415\n",
    "\n",
    "# Predict the direction of the edge\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    edge_label_index =  torch.tensor([[node_0, node_1], [node_1, node_0]], dtype=torch.long).t()\n",
    "    print(edge_label_index)\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    prediction = model.decode(z, edge_label_index)#.view(-1).sigmoid()\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
