{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#https://colab.research.google.com/drive/1N3LvAO0AXV4kBPbTMX866OwJM9YS6Ji2?usp=sharing#scrollTo=fl5W1gg5Jhzz\n",
    "\n",
    "df_players = pd.read_csv(\"./../data_scrapped/atp_players.csv\")\n",
    "df_matchs = pd.read_csv(\"./../data_formatted/training_dgl_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On construit le graph\n",
    "\n",
    "# lecture des données attendues\n",
    "# tensor1[1] -> tensor2[1] \n",
    "# le player index en tensor1 a joué contre le player au meme index en tensor 2\n",
    "# y stocke le résultat du match\n",
    "\n",
    "\n",
    "tensor1=[]\n",
    "tensor2=[]\n",
    "\n",
    "for index,row in df_players.iterrows():\n",
    "    winmatchs = df_matchs[df_matchs.player1_id == row.player_id]\n",
    "    #print(len(winmatchs))\n",
    "    if len(winmatchs) > 0:\n",
    "        #print(row.player_id)\n",
    "        for index2, row2 in winmatchs.iterrows():\n",
    "                tensor1.append(index)\n",
    "                tensor2.append(df_players.loc[df_players.player_id == row2.player2_id].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "\n",
    "labels = numpy.ones(len(tensor1))\n",
    "\n",
    "indexes = random.sample(range(0, len(tensor1)-1), ((len(tensor1)-1)//2))\n",
    "\n",
    "for index in indexes:\n",
    "    temp = tensor1[index]\n",
    "    tensor1[index] = tensor2[index]\n",
    "    tensor2[index] = temp\n",
    "    labels[index] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chbou\\AppData\\Local\\Temp\\ipykernel_27432\\1253515148.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[3446, 3], edge_index=[2, 51981], edge_label=[51981])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Create the heterogeneous graph data object:\n",
    "#data = Data()\n",
    "\n",
    "# Add the user nodes:\n",
    "x = torch.tensor(list(df_players[[\"birth_year\",\"weight_kg\",\"height_cm\"]].values),dtype=torch.float)  # [num_users, num_features_users]\n",
    "x = torch.nan_to_num(x, nan=0.0)\n",
    "#x = torch.masked_select(x, ~torch.isnan(x))\n",
    "#x = torch.ones(df_players.shape[0])\n",
    "\n",
    "edge_index = torch.stack([torch.tensor(tensor1), torch.tensor(tensor2)], dim=0)\n",
    "edge_attr = torch.Tensor(list(df_matchs[[\"player1_atprank\",\"player1_oddsB365\",\"player2_atprank\",\"player2_oddsB365\"]].values))\n",
    "#y = torch.Tensor(list(df_matchs[[\"winner_player1\"]].values))\n",
    "\n",
    "labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index,edge_label=labels) \n",
    "#data = T.ToUndirected()(data)\n",
    "# Add the movie nodes:\n",
    "#data['movie'].x = movie_features  # [num_movies, num_features_movies]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1,  ..., 1, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[3446, 3], edge_index=[2, 44184], edge_label=[44184], edge_label_index=[2, 44184]),\n",
       " Data(x=[3446, 3], edge_index=[2, 44184], edge_label=[2599], edge_label_index=[2, 2599]),\n",
       " Data(x=[3446, 3], edge_index=[2, 46783], edge_label=[5198], edge_label_index=[2, 5198]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.05,\n",
    "    num_test=0.1,\n",
    "    is_undirected=False,\n",
    "    add_negative_train_samples=False,\n",
    "    neg_sampling_ratio=0\n",
    ")(data)\n",
    "train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.7274, Val: 0.4820, Test: 0.4890\n",
      "Epoch: 002, Loss: 0.7145, Val: 0.5635, Test: 0.5625\n",
      "Epoch: 003, Loss: 0.8110, Val: 0.5674, Test: 0.5773\n",
      "Epoch: 004, Loss: 0.6966, Val: 0.4946, Test: 0.4877\n",
      "Epoch: 005, Loss: 0.7008, Val: 0.4936, Test: 0.4878\n",
      "Epoch: 006, Loss: 0.6882, Val: 0.5662, Test: 0.5639\n",
      "Epoch: 007, Loss: 0.6849, Val: 0.5666, Test: 0.5637\n",
      "Epoch: 008, Loss: 0.6862, Val: 0.5648, Test: 0.5633\n",
      "Epoch: 009, Loss: 0.6861, Val: 0.5637, Test: 0.5629\n",
      "Epoch: 010, Loss: 0.6847, Val: 0.5667, Test: 0.5637\n",
      "Epoch: 011, Loss: 0.6841, Val: 0.5641, Test: 0.5629\n",
      "Epoch: 012, Loss: 0.6844, Val: 0.5664, Test: 0.5637\n",
      "Epoch: 013, Loss: 0.6847, Val: 0.5663, Test: 0.5637\n",
      "Epoch: 014, Loss: 0.6846, Val: 0.5703, Test: 0.5635\n",
      "Epoch: 015, Loss: 0.6842, Val: 0.5639, Test: 0.5629\n",
      "Epoch: 016, Loss: 0.6840, Val: 0.5640, Test: 0.5626\n",
      "Epoch: 017, Loss: 0.6841, Val: 0.5640, Test: 0.5629\n",
      "Epoch: 018, Loss: 0.6841, Val: 0.5663, Test: 0.5637\n",
      "Epoch: 019, Loss: 0.6841, Val: 0.5669, Test: 0.5637\n",
      "Epoch: 020, Loss: 0.6840, Val: 0.5652, Test: 0.5633\n",
      "Epoch: 021, Loss: 0.6840, Val: 0.5640, Test: 0.5629\n",
      "Epoch: 022, Loss: 0.6840, Val: 0.5664, Test: 0.5637\n",
      "Epoch: 023, Loss: 0.6840, Val: 0.5670, Test: 0.5637\n",
      "Epoch: 024, Loss: 0.6839, Val: 0.5664, Test: 0.5637\n",
      "Epoch: 025, Loss: 0.6839, Val: 0.5655, Test: 0.5632\n",
      "Epoch: 026, Loss: 0.6840, Val: 0.5535, Test: 0.5612\n",
      "Epoch: 027, Loss: 0.6840, Val: 0.5574, Test: 0.5619\n",
      "Epoch: 028, Loss: 0.6839, Val: 0.5528, Test: 0.5612\n",
      "Epoch: 029, Loss: 0.6839, Val: 0.5602, Test: 0.5635\n",
      "Epoch: 030, Loss: 0.6839, Val: 0.5655, Test: 0.5638\n",
      "Epoch: 031, Loss: 0.6839, Val: 0.5655, Test: 0.5632\n",
      "Epoch: 032, Loss: 0.6839, Val: 0.5577, Test: 0.5621\n",
      "Epoch: 033, Loss: 0.6839, Val: 0.5555, Test: 0.5618\n",
      "Epoch: 034, Loss: 0.6838, Val: 0.5571, Test: 0.5627\n",
      "Epoch: 035, Loss: 0.6838, Val: 0.5537, Test: 0.5614\n",
      "Epoch: 036, Loss: 0.6838, Val: 0.5546, Test: 0.5633\n",
      "Epoch: 037, Loss: 0.6838, Val: 0.5531, Test: 0.5630\n",
      "Epoch: 038, Loss: 0.6838, Val: 0.5529, Test: 0.5627\n",
      "Epoch: 039, Loss: 0.6838, Val: 0.5552, Test: 0.5629\n",
      "Epoch: 040, Loss: 0.6838, Val: 0.5528, Test: 0.5621\n",
      "Epoch: 041, Loss: 0.6838, Val: 0.5556, Test: 0.5631\n",
      "Epoch: 042, Loss: 0.6838, Val: 0.5527, Test: 0.5621\n",
      "Epoch: 043, Loss: 0.6838, Val: 0.5527, Test: 0.5626\n",
      "Epoch: 044, Loss: 0.6838, Val: 0.5557, Test: 0.5620\n",
      "Epoch: 045, Loss: 0.6838, Val: 0.5526, Test: 0.5626\n",
      "Epoch: 046, Loss: 0.6838, Val: 0.5527, Test: 0.5627\n",
      "Epoch: 047, Loss: 0.6838, Val: 0.5556, Test: 0.5640\n",
      "Epoch: 048, Loss: 0.6838, Val: 0.5538, Test: 0.5615\n",
      "Epoch: 049, Loss: 0.6838, Val: 0.5537, Test: 0.5609\n",
      "Epoch: 050, Loss: 0.6838, Val: 0.5544, Test: 0.5617\n",
      "Epoch: 051, Loss: 0.6838, Val: 0.5538, Test: 0.5611\n",
      "Epoch: 052, Loss: 0.6838, Val: 0.5554, Test: 0.5605\n",
      "Epoch: 053, Loss: 0.6838, Val: 0.5623, Test: 0.5630\n",
      "Epoch: 054, Loss: 0.6838, Val: 0.5657, Test: 0.5634\n",
      "Epoch: 055, Loss: 0.6838, Val: 0.5622, Test: 0.5631\n",
      "Epoch: 056, Loss: 0.6838, Val: 0.5565, Test: 0.5629\n",
      "Epoch: 057, Loss: 0.6838, Val: 0.5585, Test: 0.5645\n",
      "Epoch: 058, Loss: 0.6838, Val: 0.5602, Test: 0.5623\n",
      "Epoch: 059, Loss: 0.6838, Val: 0.5633, Test: 0.5627\n",
      "Epoch: 060, Loss: 0.6838, Val: 0.5598, Test: 0.5636\n",
      "Epoch: 061, Loss: 0.6838, Val: 0.5582, Test: 0.5626\n",
      "Epoch: 062, Loss: 0.6838, Val: 0.5610, Test: 0.5625\n",
      "Epoch: 063, Loss: 0.6838, Val: 0.5622, Test: 0.5625\n",
      "Epoch: 064, Loss: 0.6838, Val: 0.5543, Test: 0.5622\n",
      "Epoch: 065, Loss: 0.6837, Val: 0.5442, Test: 0.5444\n",
      "Epoch: 066, Loss: 0.6837, Val: 0.5585, Test: 0.5617\n",
      "Epoch: 067, Loss: 0.6837, Val: 0.5597, Test: 0.5622\n",
      "Epoch: 068, Loss: 0.6837, Val: 0.5547, Test: 0.5616\n",
      "Epoch: 069, Loss: 0.6837, Val: 0.5545, Test: 0.5615\n",
      "Epoch: 070, Loss: 0.6837, Val: 0.5596, Test: 0.5653\n",
      "Epoch: 071, Loss: 0.6837, Val: 0.5548, Test: 0.5619\n",
      "Epoch: 072, Loss: 0.6837, Val: 0.5572, Test: 0.5629\n",
      "Epoch: 073, Loss: 0.6837, Val: 0.5561, Test: 0.5627\n",
      "Epoch: 074, Loss: 0.6837, Val: 0.5549, Test: 0.5606\n",
      "Epoch: 075, Loss: 0.6837, Val: 0.5583, Test: 0.5617\n",
      "Epoch: 076, Loss: 0.6837, Val: 0.5549, Test: 0.5601\n",
      "Epoch: 077, Loss: 0.6837, Val: 0.5539, Test: 0.5604\n",
      "Epoch: 078, Loss: 0.6837, Val: 0.5554, Test: 0.5606\n",
      "Epoch: 079, Loss: 0.6837, Val: 0.5586, Test: 0.5606\n",
      "Epoch: 080, Loss: 0.6837, Val: 0.5578, Test: 0.5606\n",
      "Epoch: 081, Loss: 0.6837, Val: 0.5555, Test: 0.5627\n",
      "Epoch: 082, Loss: 0.6837, Val: 0.5543, Test: 0.5601\n",
      "Epoch: 083, Loss: 0.6837, Val: 0.5577, Test: 0.5631\n",
      "Epoch: 084, Loss: 0.6837, Val: 0.5555, Test: 0.5618\n",
      "Epoch: 085, Loss: 0.6838, Val: 0.5629, Test: 0.5623\n",
      "Epoch: 086, Loss: 0.6838, Val: 0.5634, Test: 0.5627\n",
      "Epoch: 087, Loss: 0.6838, Val: 0.5573, Test: 0.5624\n",
      "Epoch: 088, Loss: 0.6837, Val: 0.5544, Test: 0.5616\n",
      "Epoch: 089, Loss: 0.6838, Val: 0.5658, Test: 0.5637\n",
      "Epoch: 090, Loss: 0.6837, Val: 0.5657, Test: 0.5636\n",
      "Epoch: 091, Loss: 0.6838, Val: 0.5658, Test: 0.5637\n",
      "Epoch: 092, Loss: 0.6837, Val: 0.5534, Test: 0.5611\n",
      "Epoch: 093, Loss: 0.6837, Val: 0.5574, Test: 0.5621\n",
      "Epoch: 094, Loss: 0.6837, Val: 0.5663, Test: 0.5640\n",
      "Epoch: 095, Loss: 0.6837, Val: 0.5632, Test: 0.5630\n",
      "Epoch: 096, Loss: 0.6837, Val: 0.5660, Test: 0.5635\n",
      "Epoch: 097, Loss: 0.6837, Val: 0.5559, Test: 0.5636\n",
      "Epoch: 098, Loss: 0.6837, Val: 0.5595, Test: 0.5618\n",
      "Epoch: 099, Loss: 0.6837, Val: 0.5609, Test: 0.5620\n",
      "Epoch: 100, Loss: 0.6837, Val: 0.5658, Test: 0.5637\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GATConv,MLP\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(3, 128, edge_dim = 4)\n",
    "        self.conv2 = GATConv(128, 64, edge_dim = 4)\n",
    "        self.mlp = MLP(in_channels=128, hidden_channels=128, out_channels=1, num_layers=3)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_label_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
    "        x = self.conv2(x, edge_index, edge_attr).relu()\n",
    "        return self.mlp(torch.cat((x[edge_label_index[0]], x[edge_label_index[1]]), dim=-1))\n",
    "    \n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index, data.edge_label_index, data.edge_attr)\n",
    "    loss = criterion(out.squeeze(), data.edge_label.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index, data.edge_label_index, data.edge_attr)\n",
    "    return roc_auc_score(data.edge_label.float(), out.squeeze())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train(train_data)\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, 'f'Test: {test_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_id                l836\n",
      "first_name               Nick\n",
      "last_name             Lindahl\n",
      "country_code              AUS\n",
      "birthdate          1988.07.31\n",
      "birth_year             1988.0\n",
      "birth_month               7.0\n",
      "birth_day                31.0\n",
      "turned_pro             2006.0\n",
      "weight_kg                77.0\n",
      "weight_lbs              170.0\n",
      "height_cm               183.0\n",
      "height_in                72.0\n",
      "birthplace      Malmo, Sweden\n",
      "Name: 3, dtype: object\n",
      "tensor([[  3, 664],\n",
      "        [664,   3]])\n",
      "tensor([0.3646, 0.6394])\n"
     ]
    }
   ],
   "source": [
    "# Specify the edge you want to predict (e.g., edge from node 0 to node 1)\n",
    "node_0 = 3\n",
    "node_1 = 664\n",
    "\n",
    "print(df_players.iloc[node_0])\n",
    "#print(df_players.iloc[node_0][\"first_name\",\"last_name\"])\n",
    "\n",
    "# Predict the direction of the edge\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    edge_label_index =  torch.tensor([[node_0, node_1], [node_1, node_0]], dtype=torch.long).t()\n",
    "    print(edge_label_index)\n",
    "    prediction = model(data.x, data.edge_index, edge_label_index, data.edge_attr).view(-1).sigmoid()\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
