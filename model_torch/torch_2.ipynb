{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#https://colab.research.google.com/drive/1N3LvAO0AXV4kBPbTMX866OwJM9YS6Ji2?usp=sharing#scrollTo=fl5W1gg5Jhzz\n",
    "\n",
    "df_players = pd.read_csv(\"./../data_scrapped/atp_players.csv\")\n",
    "df_matchs = pd.read_csv(\"./../data_formatted/training_dgl_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On construit le graph\n",
    "\n",
    "# lecture des données attendues\n",
    "# tensor1[1] -> tensor2[1] \n",
    "# le player index en tensor1 a joué contre le player au meme index en tensor 2\n",
    "# y stocke le résultat du match\n",
    "\n",
    "\n",
    "tensor1=[]\n",
    "tensor2=[]\n",
    "\n",
    "for index,row in df_players.iterrows():\n",
    "    winmatchs = df_matchs[df_matchs.player1_id == row.player_id]\n",
    "    #print(len(winmatchs))\n",
    "    if len(winmatchs) > 0:\n",
    "        #print(row.player_id)\n",
    "        for index2, row2 in winmatchs.iterrows():\n",
    "                tensor1.append(index)\n",
    "                tensor2.append(df_players.loc[df_players.player_id == row2.player2_id].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "\n",
    "labels = numpy.ones(len(tensor1))\n",
    "\n",
    "indexes = random.sample(range(0, len(tensor1)-1), ((len(tensor1)-1)//2))\n",
    "\n",
    "for index in indexes:\n",
    "    temp = tensor1[index]\n",
    "    tensor1[index] = tensor2[index]\n",
    "    tensor2[index] = temp\n",
    "    labels[index] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chbou\\AppData\\Local\\Temp\\ipykernel_27432\\1253515148.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[3446, 3], edge_index=[2, 51981], edge_label=[51981])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Create the heterogeneous graph data object:\n",
    "#data = Data()\n",
    "\n",
    "# Add the user nodes:\n",
    "x = torch.tensor(list(df_players[[\"birth_year\",\"weight_kg\",\"height_cm\"]].values),dtype=torch.float)  # [num_users, num_features_users]\n",
    "x = torch.nan_to_num(x, nan=0.0)\n",
    "#x = torch.masked_select(x, ~torch.isnan(x))\n",
    "#x = torch.ones(df_players.shape[0])\n",
    "\n",
    "edge_index = torch.stack([torch.tensor(tensor1), torch.tensor(tensor2)], dim=0)\n",
    "edge_attr = torch.Tensor(list(df_matchs[[\"player1_atprank\",\"player1_oddsB365\",\"player2_atprank\",\"player2_oddsB365\"]].values))\n",
    "#y = torch.Tensor(list(df_matchs[[\"winner_player1\"]].values))\n",
    "\n",
    "labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index,edge_label=labels) \n",
    "#data = T.ToUndirected()(data)\n",
    "# Add the movie nodes:\n",
    "#data['movie'].x = movie_features  # [num_movies, num_features_movies]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1,  ..., 1, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[3446, 3], edge_index=[2, 44184], edge_label=[44184], edge_label_index=[2, 44184]),\n",
       " Data(x=[3446, 3], edge_index=[2, 44184], edge_label=[2599], edge_label_index=[2, 2599]),\n",
       " Data(x=[3446, 3], edge_index=[2, 46783], edge_label=[5198], edge_label_index=[2, 5198]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.05,\n",
    "    num_test=0.1,\n",
    "    is_undirected=False,\n",
    "    add_negative_train_samples=False,\n",
    "    neg_sampling_ratio=0\n",
    ")(data)\n",
    "train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.7113, Val: 0.4923, Test: 0.4938\n",
      "Epoch: 002, Loss: 0.7020, Val: 0.4863, Test: 0.4940\n",
      "Epoch: 003, Loss: 0.7203, Val: 0.4902, Test: 0.4996\n",
      "Epoch: 004, Loss: 0.6930, Val: 0.5007, Test: 0.5074\n",
      "Epoch: 005, Loss: 0.6969, Val: 0.5234, Test: 0.5119\n",
      "Epoch: 006, Loss: 0.7048, Val: 0.5063, Test: 0.5179\n",
      "Epoch: 007, Loss: 0.6985, Val: 0.5107, Test: 0.5187\n",
      "Epoch: 008, Loss: 0.6982, Val: 0.5041, Test: 0.5088\n",
      "Epoch: 009, Loss: 0.6963, Val: 0.5205, Test: 0.4946\n",
      "Epoch: 010, Loss: 0.6936, Val: 0.5171, Test: 0.5107\n",
      "Epoch: 011, Loss: 0.6909, Val: 0.5136, Test: 0.4919\n",
      "Epoch: 012, Loss: 0.6924, Val: 0.4936, Test: 0.4970\n",
      "Epoch: 013, Loss: 0.6916, Val: 0.4880, Test: 0.5083\n",
      "Epoch: 014, Loss: 0.6909, Val: 0.5035, Test: 0.5003\n",
      "Epoch: 015, Loss: 0.6910, Val: 0.5097, Test: 0.5292\n",
      "Epoch: 016, Loss: 0.6909, Val: 0.5063, Test: 0.5212\n",
      "Epoch: 017, Loss: 0.6908, Val: 0.5182, Test: 0.4938\n",
      "Epoch: 018, Loss: 0.6907, Val: 0.4985, Test: 0.5142\n",
      "Epoch: 019, Loss: 0.6907, Val: 0.5175, Test: 0.5215\n",
      "Epoch: 020, Loss: 0.6908, Val: 0.5001, Test: 0.5200\n",
      "Epoch: 021, Loss: 0.6905, Val: 0.5058, Test: 0.4949\n",
      "Epoch: 022, Loss: 0.6904, Val: 0.5231, Test: 0.5138\n",
      "Epoch: 023, Loss: 0.6907, Val: 0.5158, Test: 0.4997\n",
      "Epoch: 024, Loss: 0.6906, Val: 0.4892, Test: 0.5089\n",
      "Epoch: 025, Loss: 0.6904, Val: 0.5256, Test: 0.5098\n",
      "Epoch: 026, Loss: 0.6904, Val: 0.5228, Test: 0.5333\n",
      "Epoch: 027, Loss: 0.6906, Val: 0.4999, Test: 0.5028\n",
      "Epoch: 028, Loss: 0.6906, Val: 0.4714, Test: 0.4895\n",
      "Epoch: 029, Loss: 0.6905, Val: 0.5017, Test: 0.5260\n",
      "Epoch: 030, Loss: 0.6904, Val: 0.5202, Test: 0.4971\n",
      "Epoch: 031, Loss: 0.6904, Val: 0.4903, Test: 0.5118\n",
      "Epoch: 032, Loss: 0.6904, Val: 0.5059, Test: 0.5182\n",
      "Epoch: 033, Loss: 0.6904, Val: 0.4975, Test: 0.5059\n",
      "Epoch: 034, Loss: 0.6904, Val: 0.4986, Test: 0.5050\n",
      "Epoch: 035, Loss: 0.6904, Val: 0.5064, Test: 0.5283\n",
      "Epoch: 036, Loss: 0.6904, Val: 0.5091, Test: 0.5109\n",
      "Epoch: 037, Loss: 0.6903, Val: 0.5169, Test: 0.5134\n",
      "Epoch: 038, Loss: 0.6904, Val: 0.4954, Test: 0.5050\n",
      "Epoch: 039, Loss: 0.6904, Val: 0.5165, Test: 0.5050\n",
      "Epoch: 040, Loss: 0.6904, Val: 0.5573, Test: 0.5168\n",
      "Epoch: 041, Loss: 0.6903, Val: 0.5114, Test: 0.5110\n",
      "Epoch: 042, Loss: 0.6903, Val: 0.5216, Test: 0.4950\n",
      "Epoch: 043, Loss: 0.6904, Val: 0.4895, Test: 0.5118\n",
      "Epoch: 044, Loss: 0.6903, Val: 0.4861, Test: 0.4775\n",
      "Epoch: 045, Loss: 0.6903, Val: 0.5131, Test: 0.5320\n",
      "Epoch: 046, Loss: 0.6903, Val: 0.5048, Test: 0.5113\n",
      "Epoch: 047, Loss: 0.6903, Val: 0.5228, Test: 0.5061\n",
      "Epoch: 048, Loss: 0.6903, Val: 0.5076, Test: 0.5174\n",
      "Epoch: 049, Loss: 0.6903, Val: 0.5062, Test: 0.5023\n",
      "Epoch: 050, Loss: 0.6903, Val: 0.4972, Test: 0.4992\n",
      "Epoch: 051, Loss: 0.6903, Val: 0.4779, Test: 0.4895\n",
      "Epoch: 052, Loss: 0.6903, Val: 0.5122, Test: 0.5492\n",
      "Epoch: 053, Loss: 0.6903, Val: 0.5130, Test: 0.5110\n",
      "Epoch: 054, Loss: 0.6903, Val: 0.4931, Test: 0.5035\n",
      "Epoch: 055, Loss: 0.6903, Val: 0.5277, Test: 0.5022\n",
      "Epoch: 056, Loss: 0.6903, Val: 0.4942, Test: 0.5000\n",
      "Epoch: 057, Loss: 0.6903, Val: 0.5207, Test: 0.5250\n",
      "Epoch: 058, Loss: 0.6903, Val: 0.4832, Test: 0.4949\n",
      "Epoch: 059, Loss: 0.6903, Val: 0.5039, Test: 0.5105\n",
      "Epoch: 060, Loss: 0.6903, Val: 0.5136, Test: 0.5021\n",
      "Epoch: 061, Loss: 0.6903, Val: 0.4854, Test: 0.5038\n",
      "Epoch: 062, Loss: 0.6903, Val: 0.4853, Test: 0.5252\n",
      "Epoch: 063, Loss: 0.6903, Val: 0.5092, Test: 0.5243\n",
      "Epoch: 064, Loss: 0.6903, Val: 0.4890, Test: 0.5045\n",
      "Epoch: 065, Loss: 0.6903, Val: 0.5033, Test: 0.5222\n",
      "Epoch: 066, Loss: 0.6903, Val: 0.5183, Test: 0.5050\n",
      "Epoch: 067, Loss: 0.6903, Val: 0.5101, Test: 0.5126\n",
      "Epoch: 068, Loss: 0.6903, Val: 0.5036, Test: 0.5137\n",
      "Epoch: 069, Loss: 0.6903, Val: 0.5100, Test: 0.5249\n",
      "Epoch: 070, Loss: 0.6903, Val: 0.4990, Test: 0.5164\n",
      "Epoch: 071, Loss: 0.6903, Val: 0.4908, Test: 0.5061\n",
      "Epoch: 072, Loss: 0.6903, Val: 0.4576, Test: 0.4856\n",
      "Epoch: 073, Loss: 0.6903, Val: 0.5062, Test: 0.4978\n",
      "Epoch: 074, Loss: 0.6903, Val: 0.5155, Test: 0.5047\n",
      "Epoch: 075, Loss: 0.6903, Val: 0.5129, Test: 0.5179\n",
      "Epoch: 076, Loss: 0.6903, Val: 0.4991, Test: 0.4856\n",
      "Epoch: 077, Loss: 0.6903, Val: 0.5143, Test: 0.5181\n",
      "Epoch: 078, Loss: 0.6903, Val: 0.5060, Test: 0.5066\n",
      "Epoch: 079, Loss: 0.6903, Val: 0.4846, Test: 0.4948\n",
      "Epoch: 080, Loss: 0.6903, Val: 0.5182, Test: 0.5292\n",
      "Epoch: 081, Loss: 0.6903, Val: 0.5292, Test: 0.4921\n",
      "Epoch: 082, Loss: 0.6903, Val: 0.5250, Test: 0.4922\n",
      "Epoch: 083, Loss: 0.6903, Val: 0.4973, Test: 0.5195\n",
      "Epoch: 084, Loss: 0.6903, Val: 0.5208, Test: 0.5191\n",
      "Epoch: 085, Loss: 0.6903, Val: 0.5137, Test: 0.5334\n",
      "Epoch: 086, Loss: 0.6903, Val: 0.5377, Test: 0.5258\n",
      "Epoch: 087, Loss: 0.6903, Val: 0.5091, Test: 0.4857\n",
      "Epoch: 088, Loss: 0.6903, Val: 0.5127, Test: 0.5152\n",
      "Epoch: 089, Loss: 0.6903, Val: 0.5124, Test: 0.5129\n",
      "Epoch: 090, Loss: 0.6903, Val: 0.5153, Test: 0.4869\n",
      "Epoch: 091, Loss: 0.6903, Val: 0.5188, Test: 0.5170\n",
      "Epoch: 092, Loss: 0.6903, Val: 0.5011, Test: 0.5065\n",
      "Epoch: 093, Loss: 0.6903, Val: 0.5037, Test: 0.5101\n",
      "Epoch: 094, Loss: 0.6903, Val: 0.5113, Test: 0.5030\n",
      "Epoch: 095, Loss: 0.6903, Val: 0.4775, Test: 0.5211\n",
      "Epoch: 096, Loss: 0.6903, Val: 0.5090, Test: 0.5123\n",
      "Epoch: 097, Loss: 0.6903, Val: 0.4841, Test: 0.5054\n",
      "Epoch: 098, Loss: 0.6903, Val: 0.4915, Test: 0.5120\n",
      "Epoch: 099, Loss: 0.6903, Val: 0.5178, Test: 0.5139\n",
      "Epoch: 100, Loss: 0.6903, Val: 0.5226, Test: 0.5203\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GATConv,MLP\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(3, 128, edge_dim = 4)\n",
    "        self.conv2 = GATConv(128, 64, edge_dim = 4)\n",
    "        self.mlp = MLP(in_channels=128, hidden_channels=128, out_channels=1, num_layers=3)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_label_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
    "        x = self.conv2(x, edge_index, edge_attr).relu()\n",
    "        x = self.conv3(x, edge_index, edge_attr).relu()\n",
    "        return self.mlp(torch.cat((x[edge_label_index[0]], x[edge_label_index[1]]), dim=-1))\n",
    "    \n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index, data.edge_label_index, data.edge_attr)\n",
    "    loss = criterion(out.squeeze(), data.edge_label.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index, data.edge_label_index, data.edge_attr)\n",
    "    return roc_auc_score(data.edge_label.float(), out.squeeze())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train(train_data)\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, 'f'Test: {test_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_id                l836\n",
      "first_name               Nick\n",
      "last_name             Lindahl\n",
      "country_code              AUS\n",
      "birthdate          1988.07.31\n",
      "birth_year             1988.0\n",
      "birth_month               7.0\n",
      "birth_day                31.0\n",
      "turned_pro             2006.0\n",
      "weight_kg                77.0\n",
      "weight_lbs              170.0\n",
      "height_cm               183.0\n",
      "height_in                72.0\n",
      "birthplace      Malmo, Sweden\n",
      "Name: 3, dtype: object\n",
      "tensor([[  3, 664],\n",
      "        [664,   3]])\n",
      "tensor([0.3646, 0.6394])\n"
     ]
    }
   ],
   "source": [
    "# Specify the edge you want to predict (e.g., edge from node 0 to node 1)\n",
    "node_0 = 3\n",
    "node_1 = 664\n",
    "\n",
    "print(df_players.iloc[node_0])\n",
    "#print(df_players.iloc[node_0][\"first_name\",\"last_name\"])\n",
    "\n",
    "# Predict the direction of the edge\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    edge_label_index =  torch.tensor([[node_0, node_1], [node_1, node_0]], dtype=torch.long).t()\n",
    "    print(edge_label_index)\n",
    "    prediction = model(data.x, data.edge_index, edge_label_index, data.edge_attr).view(-1).sigmoid()\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
