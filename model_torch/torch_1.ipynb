{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#https://colab.research.google.com/drive/1N3LvAO0AXV4kBPbTMX866OwJM9YS6Ji2?usp=sharing#scrollTo=fl5W1gg5Jhzz\n",
    "\n",
    "df_players = pd.read_csv(\"./../data_scrapped/atp_players.csv\")\n",
    "df_matchs = pd.read_csv(\"./../data_formatted/training_dgl_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On construit le graph\n",
    "\n",
    "# lecture des données attendues\n",
    "# tensor1[1] -> tensor2[1] \n",
    "# le player index en tensor1 a joué contre le player au meme index en tensor 2\n",
    "# y stocke le résultat du match\n",
    "\n",
    "\n",
    "tensor1=[]\n",
    "tensor2=[]\n",
    "\n",
    "for index,row in df_players.iterrows():\n",
    "    winmatchs = df_matchs[df_matchs.player1_id == row.player_id]\n",
    "    #print(len(winmatchs))\n",
    "    if len(winmatchs) > 0:\n",
    "        #print(row.player_id)\n",
    "        for index2, row2 in winmatchs.iterrows():\n",
    "                tensor1.append(index)\n",
    "                tensor2.append(df_players.loc[df_players.player_id == row2.player2_id].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "\n",
    "labels = numpy.ones(len(tensor1))\n",
    "\n",
    "indexes = random.sample(range(0, len(tensor1)-1), ((len(tensor1)-1)//2))\n",
    "\n",
    "for index in indexes:\n",
    "    temp = tensor1[index]\n",
    "    tensor1[index] = tensor2[index]\n",
    "    tensor2[index] = temp\n",
    "    labels[index] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3446, 3], edge_index=[2, 51981], edge_label=[51981])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Create the heterogeneous graph data object:\n",
    "#data = Data()\n",
    "\n",
    "# Add the user nodes:\n",
    "x = torch.tensor(list(df_players[[\"birth_year\",\"weight_kg\",\"height_cm\"]].values),dtype=torch.float)  # [num_users, num_features_users]\n",
    "x = torch.nan_to_num(x, nan=0.0)\n",
    "#x = torch.masked_select(x, ~torch.isnan(x))\n",
    "#x = torch.ones(df_players.shape[0])\n",
    "\n",
    "edge_index = torch.stack([torch.tensor(tensor1), torch.tensor(tensor2)], dim=0)\n",
    "#edge_attr = torch.Tensor(list(df_matchs[[\"player1_atprank\",\"player1_oddsB365\",\"player2_atprank\",\"player2_oddsB365\"]].values))\n",
    "#y = torch.Tensor(list(df_matchs[[\"winner_player1\"]].values))\n",
    "\n",
    "labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index,edge_label=labels) \n",
    "#data = T.ToUndirected()(data)\n",
    "# Add the movie nodes:\n",
    "#data['movie'].x = movie_features  # [num_movies, num_features_movies]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1.,  ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[3446, 3], edge_index=[2, 44184], edge_label=[44184], edge_label_index=[2, 44184]),\n",
       " Data(x=[3446, 3], edge_index=[2, 44184], edge_label=[2599], edge_label_index=[2, 2599]),\n",
       " Data(x=[3446, 3], edge_index=[2, 46783], edge_label=[5198], edge_label_index=[2, 5198]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.05,\n",
    "    num_test=0.1,\n",
    "    is_undirected=False,\n",
    "    add_negative_train_samples=False,\n",
    "    neg_sampling_ratio=0\n",
    ")(data)\n",
    "train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.7175, Val: 0.5382, Test: 0.5300\n",
      "Epoch: 002, Loss: 0.6960, Val: 0.5036, Test: 0.5092\n",
      "Epoch: 003, Loss: 0.6931, Val: 0.5024, Test: 0.5069\n",
      "Epoch: 004, Loss: 0.6927, Val: 0.5186, Test: 0.5156\n",
      "Epoch: 005, Loss: 0.6899, Val: 0.5406, Test: 0.5307\n",
      "Epoch: 006, Loss: 0.6886, Val: 0.5508, Test: 0.5411\n",
      "Epoch: 007, Loss: 0.6874, Val: 0.5490, Test: 0.5411\n",
      "Epoch: 008, Loss: 0.6871, Val: 0.5443, Test: 0.5307\n",
      "Epoch: 009, Loss: 0.6856, Val: 0.5341, Test: 0.5191\n",
      "Epoch: 010, Loss: 0.6858, Val: 0.5338, Test: 0.5178\n",
      "Epoch: 011, Loss: 0.6857, Val: 0.5353, Test: 0.5166\n",
      "Epoch: 012, Loss: 0.6846, Val: 0.5360, Test: 0.5186\n",
      "Epoch: 013, Loss: 0.6846, Val: 0.5339, Test: 0.5162\n",
      "Epoch: 014, Loss: 0.6848, Val: 0.5350, Test: 0.5171\n",
      "Epoch: 015, Loss: 0.6840, Val: 0.5351, Test: 0.5165\n",
      "Epoch: 016, Loss: 0.6838, Val: 0.5321, Test: 0.5157\n",
      "Epoch: 017, Loss: 0.6839, Val: 0.5296, Test: 0.5144\n",
      "Epoch: 018, Loss: 0.6834, Val: 0.5411, Test: 0.5219\n",
      "Epoch: 019, Loss: 0.6832, Val: 0.5403, Test: 0.5213\n",
      "Epoch: 020, Loss: 0.6831, Val: 0.5377, Test: 0.5199\n",
      "Epoch: 021, Loss: 0.6827, Val: 0.5385, Test: 0.5208\n",
      "Epoch: 022, Loss: 0.6825, Val: 0.5424, Test: 0.5244\n",
      "Epoch: 023, Loss: 0.6823, Val: 0.5448, Test: 0.5264\n",
      "Epoch: 024, Loss: 0.6820, Val: 0.5446, Test: 0.5266\n",
      "Epoch: 025, Loss: 0.6818, Val: 0.5499, Test: 0.5315\n",
      "Epoch: 026, Loss: 0.6816, Val: 0.5467, Test: 0.5287\n",
      "Epoch: 027, Loss: 0.6814, Val: 0.5466, Test: 0.5292\n",
      "Epoch: 028, Loss: 0.6810, Val: 0.5503, Test: 0.5340\n",
      "Epoch: 029, Loss: 0.6808, Val: 0.5506, Test: 0.5354\n",
      "Epoch: 030, Loss: 0.6803, Val: 0.5514, Test: 0.5374\n",
      "Epoch: 031, Loss: 0.6800, Val: 0.5538, Test: 0.5409\n",
      "Epoch: 032, Loss: 0.6796, Val: 0.5580, Test: 0.5464\n",
      "Epoch: 033, Loss: 0.6790, Val: 0.5590, Test: 0.5583\n",
      "Epoch: 034, Loss: 0.6788, Val: 0.5496, Test: 0.5544\n",
      "Epoch: 035, Loss: 0.6786, Val: 0.5517, Test: 0.5595\n",
      "Epoch: 036, Loss: 0.6806, Val: 0.5408, Test: 0.5541\n",
      "Epoch: 037, Loss: 0.6783, Val: 0.5392, Test: 0.5531\n",
      "Epoch: 038, Loss: 0.6804, Val: 0.5501, Test: 0.5611\n",
      "Epoch: 039, Loss: 0.6798, Val: 0.5750, Test: 0.5881\n",
      "Epoch: 040, Loss: 0.6805, Val: 0.5591, Test: 0.5681\n",
      "Epoch: 041, Loss: 0.6789, Val: 0.5682, Test: 0.5746\n",
      "Epoch: 042, Loss: 0.6796, Val: 0.5767, Test: 0.5780\n",
      "Epoch: 043, Loss: 0.6780, Val: 0.5797, Test: 0.5786\n",
      "Epoch: 044, Loss: 0.6786, Val: 0.5694, Test: 0.5659\n",
      "Epoch: 045, Loss: 0.6781, Val: 0.5722, Test: 0.5705\n",
      "Epoch: 046, Loss: 0.6775, Val: 0.5692, Test: 0.5676\n",
      "Epoch: 047, Loss: 0.6777, Val: 0.5658, Test: 0.5644\n",
      "Epoch: 048, Loss: 0.6772, Val: 0.5690, Test: 0.5671\n",
      "Epoch: 049, Loss: 0.6770, Val: 0.5575, Test: 0.5488\n",
      "Epoch: 050, Loss: 0.6769, Val: 0.5522, Test: 0.5443\n",
      "Epoch: 051, Loss: 0.6767, Val: 0.5606, Test: 0.5600\n",
      "Epoch: 052, Loss: 0.6765, Val: 0.5585, Test: 0.5582\n",
      "Epoch: 053, Loss: 0.6763, Val: 0.5593, Test: 0.5586\n",
      "Epoch: 054, Loss: 0.6763, Val: 0.5621, Test: 0.5615\n",
      "Epoch: 055, Loss: 0.6760, Val: 0.5625, Test: 0.5619\n",
      "Epoch: 056, Loss: 0.6759, Val: 0.5548, Test: 0.5481\n",
      "Epoch: 057, Loss: 0.6755, Val: 0.5522, Test: 0.5443\n",
      "Epoch: 058, Loss: 0.6755, Val: 0.5515, Test: 0.5427\n",
      "Epoch: 059, Loss: 0.6751, Val: 0.5488, Test: 0.5432\n",
      "Epoch: 060, Loss: 0.6748, Val: 0.5627, Test: 0.5696\n",
      "Epoch: 061, Loss: 0.6745, Val: 0.5603, Test: 0.5656\n",
      "Epoch: 062, Loss: 0.6742, Val: 0.5612, Test: 0.5645\n",
      "Epoch: 063, Loss: 0.6739, Val: 0.5516, Test: 0.5517\n",
      "Epoch: 064, Loss: 0.6741, Val: 0.5487, Test: 0.5455\n",
      "Epoch: 065, Loss: 0.6738, Val: 0.5560, Test: 0.5538\n",
      "Epoch: 066, Loss: 0.6742, Val: 0.5706, Test: 0.5665\n",
      "Epoch: 067, Loss: 0.6765, Val: 0.5735, Test: 0.5703\n",
      "Epoch: 068, Loss: 0.6764, Val: 0.5690, Test: 0.5645\n",
      "Epoch: 069, Loss: 0.6753, Val: 0.5718, Test: 0.5676\n",
      "Epoch: 070, Loss: 0.6749, Val: 0.5720, Test: 0.5689\n",
      "Epoch: 071, Loss: 0.6740, Val: 0.5723, Test: 0.5764\n",
      "Epoch: 072, Loss: 0.6748, Val: 0.5723, Test: 0.5713\n",
      "Epoch: 073, Loss: 0.6741, Val: 0.5630, Test: 0.5590\n",
      "Epoch: 074, Loss: 0.6755, Val: 0.5687, Test: 0.5653\n",
      "Epoch: 075, Loss: 0.6740, Val: 0.5461, Test: 0.5444\n",
      "Epoch: 076, Loss: 0.6744, Val: 0.5424, Test: 0.5431\n",
      "Epoch: 077, Loss: 0.6739, Val: 0.5521, Test: 0.5459\n",
      "Epoch: 078, Loss: 0.6736, Val: 0.5439, Test: 0.5432\n",
      "Epoch: 079, Loss: 0.6739, Val: 0.5278, Test: 0.5341\n",
      "Epoch: 080, Loss: 0.6728, Val: 0.5123, Test: 0.5268\n",
      "Epoch: 081, Loss: 0.6753, Val: 0.5423, Test: 0.5419\n",
      "Epoch: 082, Loss: 0.6727, Val: 0.5460, Test: 0.5450\n",
      "Epoch: 083, Loss: 0.6738, Val: 0.5400, Test: 0.5395\n",
      "Epoch: 084, Loss: 0.6741, Val: 0.5328, Test: 0.5344\n",
      "Epoch: 085, Loss: 0.6741, Val: 0.5283, Test: 0.5310\n",
      "Epoch: 086, Loss: 0.6735, Val: 0.5273, Test: 0.5282\n",
      "Epoch: 087, Loss: 0.6718, Val: 0.5172, Test: 0.5240\n",
      "Epoch: 088, Loss: 0.6712, Val: 0.5194, Test: 0.5218\n",
      "Epoch: 089, Loss: 0.6718, Val: 0.5144, Test: 0.5188\n",
      "Epoch: 090, Loss: 0.6703, Val: 0.5282, Test: 0.5303\n",
      "Epoch: 091, Loss: 0.6702, Val: 0.5102, Test: 0.5189\n",
      "Epoch: 092, Loss: 0.6700, Val: 0.5146, Test: 0.5201\n",
      "Epoch: 093, Loss: 0.6696, Val: 0.4936, Test: 0.4955\n",
      "Epoch: 094, Loss: 0.6730, Val: 0.5245, Test: 0.5119\n",
      "Epoch: 095, Loss: 0.6718, Val: 0.5464, Test: 0.5366\n",
      "Epoch: 096, Loss: 0.6709, Val: 0.4923, Test: 0.4928\n",
      "Epoch: 097, Loss: 0.6702, Val: 0.4966, Test: 0.4939\n",
      "Epoch: 098, Loss: 0.6694, Val: 0.5076, Test: 0.4989\n",
      "Epoch: 099, Loss: 0.6694, Val: 0.4979, Test: 0.4888\n",
      "Epoch: 100, Loss: 0.6692, Val: 0.4880, Test: 0.4842\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv,MLP\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(3, 128)\n",
    "        self.conv2 = SAGEConv(128, 64)\n",
    "        self.mlp = MLP(in_channels=128, hidden_channels=128, out_channels=1, num_layers=3)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_label_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return self.mlp(torch.cat((x[edge_label_index[0]], x[edge_label_index[1]]), dim=-1))\n",
    "    \n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index, data.edge_label_index)\n",
    "    loss = criterion(out.squeeze(), data.edge_label.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index, data.edge_label_index)\n",
    "    return roc_auc_score(data.edge_label.float(), out.squeeze())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train(train_data)\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, 'f'Test: {test_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_id                l836\n",
      "first_name               Nick\n",
      "last_name             Lindahl\n",
      "country_code              AUS\n",
      "birthdate          1988.07.31\n",
      "birth_year             1988.0\n",
      "birth_month               7.0\n",
      "birth_day                31.0\n",
      "turned_pro             2006.0\n",
      "weight_kg                77.0\n",
      "weight_lbs              170.0\n",
      "height_cm               183.0\n",
      "height_in                72.0\n",
      "birthplace      Malmo, Sweden\n",
      "Name: 3, dtype: object\n",
      "tensor([[  3, 664],\n",
      "        [664,   3]])\n",
      "tensor([0.9444, 0.9608])\n"
     ]
    }
   ],
   "source": [
    "# Specify the edge you want to predict (e.g., edge from node 0 to node 1)\n",
    "node_0 = 3\n",
    "node_1 = 664\n",
    "\n",
    "print(df_players.iloc[node_0])\n",
    "#print(df_players.iloc[node_0][\"first_name\",\"last_name\"])\n",
    "\n",
    "# Predict the direction of the edge\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    edge_label_index =  torch.tensor([[node_0, node_1], [node_1, node_0]], dtype=torch.long).t()\n",
    "    print(edge_label_index)\n",
    "    prediction = model(data.x, data.edge_index, edge_label_index).view(-1).sigmoid()\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
